{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827d9368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from google.cloud import language_v1\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set Google NLP API key\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = r\"C:\\Users\\User\\Desktop\\Pratt\\2025spring\\ADV project\\final project\\nlp-project-459218-a7af92faf71f.json\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb11ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize sentiment analysis tools\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "google_client = language_v1.LanguageServiceClient()\n",
    "\n",
    "# Track total number of API calls\n",
    "total_api_calls = 0\n",
    "\n",
    "# Google NLP sentiment analysis function (with API call counter)\n",
    "def get_google_sentiment(text):\n",
    "    global total_api_calls\n",
    "    document = language_v1.Document(content=text, type_=language_v1.Document.Type.PLAIN_TEXT)\n",
    "    try:\n",
    "        response = google_client.analyze_sentiment(request={\"document\": document})\n",
    "        sentiment = response.document_sentiment\n",
    "        total_api_calls += 1\n",
    "        return sentiment.score\n",
    "    except:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e006aa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path and session numbers\n",
    "base_path = r\"C:\\Users\\User\\Desktop\\Pratt\\2025spring\\ADV project\\final project data\"\n",
    "sessions = [1, 2, 3, 4, 5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c150757e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ ËôïÁêÜ Session 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Session 1 Google NLP: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 388/388 [00:39<00:00,  9.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Session 1 ÂÑ≤Â≠òÂÆåÊàê ‚Üí C:\\Users\\User\\Desktop\\Pratt\\2025spring\\ADV project\\final project data\\session_1_with_sentiment.csv\n",
      "\n",
      "üìÑ ËôïÁêÜ Session 2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Session 2 Google NLP: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 383/383 [00:40<00:00,  9.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Session 2 ÂÑ≤Â≠òÂÆåÊàê ‚Üí C:\\Users\\User\\Desktop\\Pratt\\2025spring\\ADV project\\final project data\\session_2_with_sentiment.csv\n",
      "\n",
      "üìÑ ËôïÁêÜ Session 3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Session 3 Google NLP: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 374/374 [00:36<00:00, 10.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Session 3 ÂÑ≤Â≠òÂÆåÊàê ‚Üí C:\\Users\\User\\Desktop\\Pratt\\2025spring\\ADV project\\final project data\\session_3_with_sentiment.csv\n",
      "\n",
      "üìÑ ËôïÁêÜ Session 4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Session 4 Google NLP: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 382/382 [00:37<00:00, 10.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Session 4 ÂÑ≤Â≠òÂÆåÊàê ‚Üí C:\\Users\\User\\Desktop\\Pratt\\2025spring\\ADV project\\final project data\\session_4_with_sentiment.csv\n",
      "\n",
      "üìÑ ËôïÁêÜ Session 5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Session 5 Google NLP: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 380/380 [00:37<00:00, 10.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Session 5 ÂÑ≤Â≠òÂÆåÊàê ‚Üí C:\\Users\\User\\Desktop\\Pratt\\2025spring\\ADV project\\final project data\\session_5_with_sentiment.csv\n",
      "\n",
      "üìÑ ËôïÁêÜ Session 6 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Session 6 Google NLP: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 301/301 [00:29<00:00, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Session 6 ÂÑ≤Â≠òÂÆåÊàê ‚Üí C:\\Users\\User\\Desktop\\Pratt\\2025spring\\ADV project\\final project data\\session_6_with_sentiment.csv\n",
      "\n",
      "üìä Êú¨Ê¨°Á∏ΩÂÖ±‰ΩøÁî® Google NLP API ÂàÜÊûêÔºö2198 Ê¨°\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Process each session\n",
    "for session_num in sessions:\n",
    "    print(f\"\\nüìÑ Processing Session {session_num} ...\")\n",
    "    \n",
    "    input_file = os.path.join(base_path, f\"In_Treatment_Session {session_num}.xlsx\")\n",
    "    output_file = os.path.join(base_path, f\"session_{session_num}_with_sentiment.csv\")\n",
    "\n",
    "    # Read file and clean format\n",
    "    df = pd.read_excel(input_file)\n",
    "    df['Speaker'] = df['Speaker'].astype(str).str.strip()\n",
    "    df['Start Time'] = df['Start Time'].apply(lambda x: str(x).split(' --> ')[0])\n",
    "    df['Start Time'] = pd.to_datetime(df['Start Time'], format='%H:%M:%S,%f')\n",
    "\n",
    "    # Apply three sentiment analysis models\n",
    "    df['TextBlob_Score'] = df['Dialogue'].apply(lambda x: TextBlob(str(x)).sentiment.polarity)\n",
    "    df['VADER_Score'] = df['Dialogue'].apply(lambda x: vader.polarity_scores(str(x))['compound'])\n",
    "    df['Google_Score'] = [get_google_sentiment(str(x)) for x in tqdm(df['Dialogue'], desc=f\"Session {session_num} Google NLP\")]\n",
    "\n",
    "    # Save results\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"‚úÖ Session {session_num} saved ‚Üí {output_file}\")\n",
    "\n",
    "# üî¢ Display total API usage count\n",
    "print(f\"\\nüìä Total number of Google NLP API calls used: {total_api_calls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655aab80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "import os\n",
    "\n",
    "# Set default renderer to display in browser\n",
    "pio.renderers.default = \"browser\"\n",
    "\n",
    "# Session configuration\n",
    "sessions = [1, 2, 3, 4, 5, 6]\n",
    "base_path = r\"C:\\Users\\User\\Desktop\\Pratt\\2025spring\\ADV project\\final project data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c8fd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color settings for different speakers and models\n",
    "colors = {\n",
    "    \"Paul_TextBlob\": \"#87CEFA\",\n",
    "    \"Paul_VADER\": \"#9370DB\",\n",
    "    \"Paul_Google\": \"#4682B4\",\n",
    "    \"Laura_TextBlob\": \"#FF6F61\",\n",
    "    \"Laura_VADER\": \"#FFA500\",\n",
    "    \"Laura_Google\": \"#228B22\"\n",
    "}\n",
    "\n",
    "# Create subplot layout\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=2,\n",
    "    subplot_titles=[f\"Session {i}\" for i in sessions],\n",
    "    shared_xaxes=False,\n",
    "    shared_yaxes=False,\n",
    "    vertical_spacing=0.20,\n",
    "    horizontal_spacing=0.02\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbda003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each session CSV\n",
    "for idx, session_num in enumerate(sessions, start=1):\n",
    "    file_path = os.path.join(base_path, f\"session_{session_num}_with_sentiment.csv\")\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    df['Start Time'] = pd.to_datetime(df['Start Time'])\n",
    "    row = (idx - 1) // 2 + 1\n",
    "    col = (idx - 1) % 2 + 1\n",
    "    show_legend = (idx == 1)\n",
    "\n",
    "    for speaker in ['Paul', 'Laura']:\n",
    "        for model in ['TextBlob', 'VADER', 'Google']:\n",
    "            score_col = f\"{model}_Score\"\n",
    "            sub_df = df[df['Speaker'] == speaker]\n",
    "\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=sub_df['Start Time'],\n",
    "                    y=sub_df[score_col],\n",
    "                    mode='lines+markers',\n",
    "                    name=f\"{speaker} - {model}\",\n",
    "                    legendgroup=f\"{speaker}-{model}\",\n",
    "                    showlegend=show_legend,\n",
    "                    marker=dict(size=4, color=colors[f\"{speaker}_{model}\"]),\n",
    "                    line=dict(width=2, color=colors[f\"{speaker}_{model}\"]),\n",
    "                    text=[f\"{speaker}: {text}\" for text in sub_df['Dialogue']],\n",
    "                    hoverinfo='text+x+y'\n",
    "                ),\n",
    "                row=row, col=col\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3759eb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update layout settings\n",
    "fig.update_layout(\n",
    "    height=1200,\n",
    "    width=1800,\n",
    "    title=dict(\n",
    "        text=\"In Treatment Sessions 1‚Äì6: Sentiment Comparison (TextBlob vs VADER vs Google NLP)\",\n",
    "        x=0.5,\n",
    "        xanchor='center',\n",
    "        font=dict(size=24)\n",
    "    ),\n",
    "    template=\"simple_white\",\n",
    "    hovermode=\"closest\",\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=1.02,\n",
    "        xanchor=\"center\",\n",
    "        x=0.5\n",
    "    ),\n",
    "    margin=dict(b=150)  \n",
    ")\n",
    "\n",
    "# Add chart usage tips\n",
    "fig.add_annotation(\n",
    "    text=(\n",
    "        \"<b>Chart Tips:</b> \"\n",
    "        \"Click legend items to show/hide lines ¬∑ \"\n",
    "        \"Drag to zoom in ¬∑ Use top-right menu to reset view\"\n",
    "    ),\n",
    "    xref=\"paper\", yref=\"paper\",\n",
    "    x=1.0, y=1.15,\n",
    "    showarrow=False,\n",
    "    font=dict(size=13, color=\"gray\"),\n",
    "    align=\"right\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e9620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format x-axis to show time\n",
    "for axis in fig.layout:\n",
    "    if axis.startswith(\"xaxis\"):\n",
    "        fig.layout[axis].tickformat = \"%H:%M:%S\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1661051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and display chart\n",
    "fig.write_html(\"textblob_vader_google_with_tips.html\", full_html=True, include_plotlyjs=\"cdn\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
